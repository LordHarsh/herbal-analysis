{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from mlxtend.frequent_patterns import association_rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing\n",
    "data = pd.read_csv(r'../initial-data/Herbals and preperations.csv', encoding='latin-1')\n",
    "data = data.apply(lambda x: x.str.lower() if x.dtype == \"object\" else x)\n",
    "data=data.dropna(subset=['bot_name'])\n",
    "data['bot_name'] = data['bot_name'].str.strip()\n",
    "\n",
    "data['author'] = data['author'].dropna(axis=0).str.strip()\n",
    "data = data.apply(lambda x: x.str.lower() if x.dtype == \"object\" else x)\n",
    "data=data.dropna(subset=['bot_name'])\n",
    "data['bot_name'] = data['bot_name'].str.strip()\n",
    "columns_to_remove = ['herb_part', 'taste', 'potency', 'ultimate_taste', 'inherent_action']\n",
    "data = data.drop(columns=columns_to_remove)\n",
    "\n",
    "data.loc[data.bot_name.isin(['terminalia chebula', 'terminalia bellarica', 'phyllanthus emblica']), 'bot_name'] = 'triphala'\n",
    "data.loc[data.bot_name.isin(['piper nigrum', 'piper longum', 'zingiber officinale']), 'bot_name'] = 'trikatu'\n",
    "data.loc[(data.disease_category == 'diabetes') & (data.bot_name == 'saccharum officinarum'), 'bot_name'] = 'tinospora cordifolia'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert all unique values in bot_name to a new series to be used as id\n",
    "bot_name = data['bot_name'].unique()\n",
    "bot_name = pd.Series(bot_name)\n",
    "bot_name = bot_name.reset_index()\n",
    "bot_name.columns = ['id', 'bot_name']\n",
    "bot_name['id'] = bot_name['id'] + 1\n",
    "if not os.path.exists(f'./split-data'):\n",
    "    os.makedirs(f'./split-data')\n",
    "bot_name.to_csv(r'./split-data/ids.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting\n",
    "\n",
    "data_dia = data.loc[data['disease_category'].apply(lambda x: x in ['diab/ tb ', 'diabetes'])].copy()\n",
    "data_tub =  data.loc[data['disease_category'].apply(lambda x: x in ['diab/ tb ', 'tuberculosis '])].copy()\n",
    "data_dia_aga = data_dia.loc[data_dia['author'].apply(lambda x: x in ['agathiyar'])]\n",
    "data_dia_the = data_dia.loc[data_dia['author'].apply(lambda x: x in ['therayar'])]\n",
    "data_tub_aga = data_tub.loc[data_tub['author'].apply(lambda x: x in ['agathiyar'])]\n",
    "data_tub_the = data_tub.loc[data_tub['author'].apply(lambda x: x in ['therayar'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_split_data(data, name):\n",
    "    # group using the id instead of name\n",
    "    data = pd.merge(data, bot_name, on='bot_name', how='left')\n",
    "    # Groupby drug and output id of all bot_names instead of name in the text file\n",
    "    def remove_duplicates(row):\n",
    "        numbers = row.split()\n",
    "        unique_numbers = list(set(numbers))\n",
    "        return ' '.join(unique_numbers)\n",
    "    grouped_data = data.groupby('drug')['id'].apply(lambda x: ' '.join(x.astype(str))).reset_index()\n",
    "    grouped_data['id'] = grouped_data['id'].apply(remove_duplicates)\n",
    "    # grouped_data = data.groupby('drug')['bot_name'].apply(lambda x: ' '.join(x)).reset_index()\n",
    "    # grouped_data\n",
    "    # # Save the result to a text file\n",
    "    with open(f'./split-data/{name}.txt', 'w') as f:\n",
    "        for index, row in grouped_data.iterrows():\n",
    "            f.write(row['id'] + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = {\n",
    "    'Diabetic-Data-Overall': data_dia,\n",
    "    'Diabetic-Data-Agathiyar': data_dia_aga,\n",
    "    'Diabetic-Data-Therayar': data_dia_the,\n",
    "    'Tuberculosis-Data-Overall': data_tub,\n",
    "    'Tuberculosis-Data-Agathiyar': data_tub_aga,\n",
    "    'Tuberculosis-Data-Therayar': data_tub_the\n",
    "    }\n",
    "for name, data in all_data.items():\n",
    "    write_split_data(data, name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def runSPMF(algorithm, data, name):\n",
    "    # Create algorithm folder if not exists\n",
    "    if not os.path.exists(f'./output-data/{algorithm}'):\n",
    "        os.makedirs(f'./output-data/{algorithm}')\n",
    "    # Run SPMF\n",
    "    os.system( f\"java -jar spmf.jar run {algorithm} ./split-data/{name}.txt ./output-data/{algorithm}/{name}.txt 5%\")\n",
    "    # Read the result from the output txt file\n",
    "    with open(f'./output-data/{algorithm}/{name}.txt', 'r') as f:\n",
    "        # Read output in format => 52 53  #SUP: \n",
    "        result = f.read()\n",
    "    # Split the result into lines\n",
    "    result = result.split('\\n')\n",
    "    out_dic = {}\n",
    "    for row in result:\n",
    "        # Get the bot_name and support value\n",
    "        if not row:\n",
    "            continue\n",
    "        values = row.split(' #SUP: ')\n",
    "        out_dic[str(values[0])] = values[1]\n",
    "    # Out_dic to df\n",
    "    out_df = pd.DataFrame.from_dict(out_dic, orient='index').reset_index()\n",
    "    # Rename columns\n",
    "    out_df.columns = ['bot_name', 'support']\n",
    "    \n",
    "    def to_bot_name(row):\n",
    "        ids = row.split()\n",
    "        bot_names = []\n",
    "        for id in ids:\n",
    "            bot_names.append(bot_name.loc[bot_name['id'] == int(id), 'bot_name'].values[0])\n",
    "        return bot_names\n",
    "    \n",
    "    # out_df['bot_name'] = out_df['bot_name'].apply(to_bot_name)\n",
    "    \n",
    "    return out_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">/media/harsh/Docs Volume/Documents/Data Science Community/herbal-analysis/spmf/spmf.jar\n",
      "=============  APRIORI - STATS =============\n",
      " Candidates count : 903\n",
      " The algorithm stopped at size 3\n",
      " Frequent itemsets count : 44\n",
      " Maximum memory usage : 7.8136444091796875 mb\n",
      " Total time ~ 22 ms\n",
      "===================================================\n",
      ">/media/harsh/Docs Volume/Documents/Data Science Community/herbal-analysis/spmf/spmf.jar\n",
      "=============  FP-GROWTH 2.42 - STATS =============\n",
      " Transactions count from database : 58\n",
      " Max memory usage: 8.028984069824219 mb \n",
      " Frequent itemsets count : 278\n",
      " Total time ~ 25 ms\n",
      "===================================================\n",
      ">/media/harsh/Docs Volume/Documents/Data Science Community/herbal-analysis/spmf/spmf.jar\n",
      "=============  APRIORI TID v2.12 - STATS =============\n",
      " Transactions count from database : 58\n",
      " Frequent itemsets count : 278\n",
      " Maximum memory usage : 7.8110809326171875 mb\n",
      " Total time ~ 22 ms\n",
      "===================================================\n",
      ">/media/harsh/Docs Volume/Documents/Data Science Community/herbal-analysis/spmf/spmf.jar\n",
      "========== RELIM - STATS ============\n",
      " Number of frequent  itemsets: 278\n",
      " Total time ~: 738 ms\n",
      " Max memory:92.00166320800781\n",
      "=====================================\n",
      ">/media/harsh/Docs Volume/Documents/Data Science Community/herbal-analysis/spmf/spmf.jar\n",
      "=============  ECLAT v0.96r18 - STATS =============\n",
      " Transactions count from database : 58\n",
      " Frequent itemsets count : 278\n",
      " Total time ~ 21 ms\n",
      " Maximum memory usage : 8.028984069824219 mb\n",
      "===================================================\n",
      ">/media/harsh/Docs Volume/Documents/Data Science Community/herbal-analysis/spmf/spmf.jar\n",
      "=============  APRIORI - STATS =============\n",
      " Candidates count : 600\n",
      " The algorithm stopped at size 5\n",
      " Frequent itemsets count : 46\n",
      " Maximum memory usage : 7.8110809326171875 mb\n",
      " Total time ~ 9 ms\n",
      "===================================================\n",
      ">/media/harsh/Docs Volume/Documents/Data Science Community/herbal-analysis/spmf/spmf.jar\n",
      "=============  FP-GROWTH 2.42 - STATS =============\n",
      " Transactions count from database : 34\n",
      " Max memory usage: 8.29095458984375 mb \n",
      " Frequent itemsets count : 2357\n",
      " Total time ~ 34 ms\n",
      "===================================================\n",
      ">/media/harsh/Docs Volume/Documents/Data Science Community/herbal-analysis/spmf/spmf.jar\n",
      "=============  APRIORI TID v2.12 - STATS =============\n",
      " Transactions count from database : 34\n",
      " Frequent itemsets count : 2357\n",
      " Maximum memory usage : 7.8110809326171875 mb\n",
      " Total time ~ 64 ms\n",
      "===================================================\n",
      ">/media/harsh/Docs Volume/Documents/Data Science Community/herbal-analysis/spmf/spmf.jar\n",
      "========== RELIM - STATS ============\n",
      " Number of frequent  itemsets: 2357\n",
      " Total time ~: 293 ms\n",
      " Max memory:73.51021575927734\n",
      "=====================================\n",
      ">/media/harsh/Docs Volume/Documents/Data Science Community/herbal-analysis/spmf/spmf.jar\n",
      "=============  ECLAT v0.96r18 - STATS =============\n",
      " Transactions count from database : 34\n",
      " Frequent itemsets count : 2357\n",
      " Total time ~ 31 ms\n",
      " Maximum memory usage : 8.811027526855469 mb\n",
      "===================================================\n",
      ">/media/harsh/Docs Volume/Documents/Data Science Community/herbal-analysis/spmf/spmf.jar\n",
      "=============  APRIORI - STATS =============\n",
      " Candidates count : 1082\n",
      " The algorithm stopped at size 4\n",
      " Frequent itemsets count : 51\n",
      " Maximum memory usage : 7.8110809326171875 mb\n",
      " Total time ~ 14 ms\n",
      "===================================================\n",
      ">/media/harsh/Docs Volume/Documents/Data Science Community/herbal-analysis/spmf/spmf.jar\n",
      "=============  FP-GROWTH 2.42 - STATS =============\n",
      " Transactions count from database : 25\n",
      " Max memory usage: 8.028984069824219 mb \n",
      " Frequent itemsets count : 456\n",
      " Total time ~ 18 ms\n",
      "===================================================\n",
      ">/media/harsh/Docs Volume/Documents/Data Science Community/herbal-analysis/spmf/spmf.jar\n",
      "=============  APRIORI TID v2.12 - STATS =============\n",
      " Transactions count from database : 25\n",
      " Frequent itemsets count : 456\n",
      " Maximum memory usage : 7.8111572265625 mb\n",
      " Total time ~ 31 ms\n",
      "===================================================\n",
      ">/media/harsh/Docs Volume/Documents/Data Science Community/herbal-analysis/spmf/spmf.jar\n",
      "========== RELIM - STATS ============\n",
      " Number of frequent  itemsets: 456\n",
      " Total time ~: 211 ms\n",
      " Max memory:52.51433563232422\n",
      "=====================================\n",
      ">/media/harsh/Docs Volume/Documents/Data Science Community/herbal-analysis/spmf/spmf.jar\n",
      "=============  ECLAT v0.96r18 - STATS =============\n",
      " Transactions count from database : 25\n",
      " Frequent itemsets count : 456\n",
      " Total time ~ 12 ms\n",
      " Maximum memory usage : 8.028984069824219 mb\n",
      "===================================================\n",
      ">/media/harsh/Docs Volume/Documents/Data Science Community/herbal-analysis/spmf/spmf.jar\n",
      "=============  APRIORI - STATS =============\n",
      " Candidates count : 1327\n",
      " The algorithm stopped at size 3\n",
      " Frequent itemsets count : 56\n",
      " Maximum memory usage : 7.8110809326171875 mb\n",
      " Total time ~ 15 ms\n",
      "===================================================\n",
      ">/media/harsh/Docs Volume/Documents/Data Science Community/herbal-analysis/spmf/spmf.jar\n",
      "=============  FP-GROWTH 2.42 - STATS =============\n",
      " Transactions count from database : 32\n",
      " Max memory usage: 8.551055908203125 mb \n",
      " Frequent itemsets count : 1615\n",
      " Total time ~ 34 ms\n",
      "===================================================\n",
      ">/media/harsh/Docs Volume/Documents/Data Science Community/herbal-analysis/spmf/spmf.jar\n",
      "=============  APRIORI TID v2.12 - STATS =============\n",
      " Transactions count from database : 32\n",
      " Frequent itemsets count : 1615\n",
      " Maximum memory usage : 7.811073303222656 mb\n",
      " Total time ~ 77 ms\n",
      "===================================================\n",
      ">/media/harsh/Docs Volume/Documents/Data Science Community/herbal-analysis/spmf/spmf.jar\n",
      "========== RELIM - STATS ============\n",
      " Number of frequent  itemsets: 1615\n",
      " Total time ~: 711 ms\n",
      " Max memory:100.02296447753906\n",
      "=====================================\n",
      ">/media/harsh/Docs Volume/Documents/Data Science Community/herbal-analysis/spmf/spmf.jar\n",
      "=============  ECLAT v0.96r18 - STATS =============\n",
      " Transactions count from database : 32\n",
      " Frequent itemsets count : 1615\n",
      " Total time ~ 26 ms\n",
      " Maximum memory usage : 8.550994873046875 mb\n",
      "===================================================\n",
      ">/media/harsh/Docs Volume/Documents/Data Science Community/herbal-analysis/spmf/spmf.jar\n",
      "=============  APRIORI - STATS =============\n",
      " Candidates count : 465\n",
      " The algorithm stopped at size 2\n",
      " Frequent itemsets count : 30\n",
      " Maximum memory usage : 7.8110809326171875 mb\n",
      " Total time ~ 8 ms\n",
      "===================================================\n",
      ">/media/harsh/Docs Volume/Documents/Data Science Community/herbal-analysis/spmf/spmf.jar\n",
      "=============  FP-GROWTH 2.42 - STATS =============\n",
      " Transactions count from database : 21\n",
      " Max memory usage: 7.812049865722656 mb \n",
      " Frequent itemsets count : 248\n",
      " Total time ~ 16 ms\n",
      "===================================================\n",
      ">/media/harsh/Docs Volume/Documents/Data Science Community/herbal-analysis/spmf/spmf.jar\n",
      "=============  APRIORI TID v2.12 - STATS =============\n",
      " Transactions count from database : 21\n",
      " Frequent itemsets count : 248\n",
      " Maximum memory usage : 7.551063537597656 mb\n",
      " Total time ~ 28 ms\n",
      "===================================================\n",
      ">/media/harsh/Docs Volume/Documents/Data Science Community/herbal-analysis/spmf/spmf.jar\n",
      "========== RELIM - STATS ============\n",
      " Number of frequent  itemsets: 248\n",
      " Total time ~: 63 ms\n",
      " Max memory:14.028984069824219\n",
      "=====================================\n",
      ">/media/harsh/Docs Volume/Documents/Data Science Community/herbal-analysis/spmf/spmf.jar\n",
      "=============  ECLAT v0.96r18 - STATS =============\n",
      " Transactions count from database : 21\n",
      " Frequent itemsets count : 248\n",
      " Total time ~ 8 ms\n",
      " Maximum memory usage : 7.813682556152344 mb\n",
      "===================================================\n",
      ">/media/harsh/Docs Volume/Documents/Data Science Community/herbal-analysis/spmf/spmf.jar\n",
      "=============  APRIORI - STATS =============\n",
      " Candidates count : 3130\n",
      " The algorithm stopped at size 7\n",
      " Frequent itemsets count : 269\n",
      " Maximum memory usage : 8.028984069824219 mb\n",
      " Total time ~ 31 ms\n",
      "===================================================\n",
      ">/media/harsh/Docs Volume/Documents/Data Science Community/herbal-analysis/spmf/spmf.jar\n",
      "=============  FP-GROWTH 2.42 - STATS =============\n",
      " Transactions count from database : 13\n",
      " Max memory usage: 40.53093719482422 mb \n",
      " Frequent itemsets count : 4277305\n",
      " Total time ~ 5714 ms\n",
      "===================================================\n",
      ">/media/harsh/Docs Volume/Documents/Data Science Community/herbal-analysis/spmf/spmf.jar\n"
     ]
    }
   ],
   "source": [
    "all_data_itemset = {}\n",
    "for name, data in all_data.items():\n",
    "    all_data_itemset['Apriori_'+ name] = runSPMF('Apriori', data, name)\n",
    "    all_data_itemset['FPGrowth_itemsets_' + name] = runSPMF('FPGrowth_itemsets', data, name)\n",
    "    all_data_itemset['Apriori_TID_' + name] = runSPMF('Apriori_TID', data, name)\n",
    "    all_data_itemset['Relim_' + name] = runSPMF('Relim', data, name)\n",
    "    all_data_itemset['Eclat_' + name] = runSPMF('Eclat', data, name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_association_rules(df: pd.DataFrame, name: str, min_threshold: float = 0.7):\n",
    "    df = df.copy()\n",
    "    df['bot_name'] = df['bot_name'].str.split()\n",
    "\n",
    "    # Convert the 'support' column to integers\n",
    "    df['support'] = df['support'].astype(int)\n",
    "\n",
    "    # Convert the 'bot_name' lists to frozensets\n",
    "    df['bot_name'] = df['bot_name'].apply(frozenset)\n",
    "    df.rename(columns={'bot_name': 'itemsets'}, inplace=True)\n",
    "    # Generate frequent itemsets using the 'bot_name' column\n",
    "    # Create association rules\n",
    "    rules = association_rules(df, metric='confidence', min_threshold=min_threshold)\n",
    "    while rules.empty and min_threshold > 0:\n",
    "        min_threshold = max(min_threshold - 0.3, 0)\n",
    "        rules = association_rules(df, metric='confidence', min_threshold=min_threshold)\n",
    "        \n",
    "    # If still empty print it in red color\n",
    "    if rules.empty:\n",
    "        print('\\033[91m' + f'No rules found for {name} with min_threshold {min_threshold}' + '\\033[0m')\n",
    "    # Display the generated association rules\n",
    "    return rules\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[91mNo rules found for Apriori_Diabetic-Data-Overall with min_threshold 0\u001b[0m\n",
      "\u001b[91mNo rules found for Apriori_Diabetic-Data-Agathiyar with min_threshold 0\u001b[0m\n",
      "\u001b[91mNo rules found for Apriori_Diabetic-Data-Therayar with min_threshold 0\u001b[0m\n",
      "\u001b[91mNo rules found for Apriori_Tuberculosis-Data-Overall with min_threshold 0\u001b[0m\n",
      "\u001b[91mNo rules found for Apriori_Tuberculosis-Data-Agathiyar with min_threshold 0\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "association_rules_dic = {}\n",
    "for name, df in all_data_itemset.items():\n",
    "    association_rules_dic[name] = create_association_rules(df, name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Apriori_Diabetic-Data-Overall': Empty DataFrame\n",
       " Columns: [antecedents, consequents, antecedent support, consequent support, support, confidence, lift, leverage, conviction, zhangs_metric]\n",
       " Index: [],\n",
       " 'FPGrowth_itemsets_Diabetic-Data-Overall': Empty DataFrame\n",
       " Columns: [antecedents, consequents, antecedent support, consequent support, support, confidence, lift, leverage, conviction, zhangs_metric]\n",
       " Index: [],\n",
       " 'Apriori_TID_Diabetic-Data-Overall': Empty DataFrame\n",
       " Columns: [antecedents, consequents, antecedent support, consequent support, support, confidence, lift, leverage, conviction, zhangs_metric]\n",
       " Index: [],\n",
       " 'Relim_Diabetic-Data-Overall': Empty DataFrame\n",
       " Columns: [antecedents, consequents, antecedent support, consequent support, support, confidence, lift, leverage, conviction, zhangs_metric]\n",
       " Index: [],\n",
       " 'Eclat_Diabetic-Data-Overall': Empty DataFrame\n",
       " Columns: [antecedents, consequents, antecedent support, consequent support, support, confidence, lift, leverage, conviction, zhangs_metric]\n",
       " Index: [],\n",
       " 'Apriori_Diabetic-Data-Agathiyar': Empty DataFrame\n",
       " Columns: [antecedents, consequents, antecedent support, consequent support, support, confidence, lift, leverage, conviction, zhangs_metric]\n",
       " Index: [],\n",
       " 'FPGrowth_itemsets_Diabetic-Data-Agathiyar': Empty DataFrame\n",
       " Columns: [antecedents, consequents, antecedent support, consequent support, support, confidence, lift, leverage, conviction, zhangs_metric]\n",
       " Index: [],\n",
       " 'Apriori_TID_Diabetic-Data-Agathiyar': Empty DataFrame\n",
       " Columns: [antecedents, consequents, antecedent support, consequent support, support, confidence, lift, leverage, conviction, zhangs_metric]\n",
       " Index: [],\n",
       " 'Relim_Diabetic-Data-Agathiyar': Empty DataFrame\n",
       " Columns: [antecedents, consequents, antecedent support, consequent support, support, confidence, lift, leverage, conviction, zhangs_metric]\n",
       " Index: [],\n",
       " 'Eclat_Diabetic-Data-Agathiyar': Empty DataFrame\n",
       " Columns: [antecedents, consequents, antecedent support, consequent support, support, confidence, lift, leverage, conviction, zhangs_metric]\n",
       " Index: [],\n",
       " 'Apriori_Diabetic-Data-Therayar': Empty DataFrame\n",
       " Columns: [antecedents, consequents, antecedent support, consequent support, support, confidence, lift, leverage, conviction, zhangs_metric]\n",
       " Index: [],\n",
       " 'FPGrowth_itemsets_Diabetic-Data-Therayar':   antecedents consequents  antecedent support  consequent support  support  \\\n",
       " 0        (65)         (6)                 4.0                11.0      4.0   \n",
       " 1        (67)         (6)                 6.0                11.0      5.0   \n",
       " 2        (53)         (6)                 6.0                11.0      5.0   \n",
       " 3        (52)        (53)                 8.0                 6.0      6.0   \n",
       " 4        (53)        (52)                 6.0                 8.0      6.0   \n",
       " 5    (52, 53)         (6)                 6.0                11.0      5.0   \n",
       " 6     (52, 6)        (53)                 5.0                 6.0      5.0   \n",
       " 7     (53, 6)        (52)                 5.0                 8.0      5.0   \n",
       " 8        (53)     (52, 6)                 6.0                 5.0      5.0   \n",
       " \n",
       "    confidence      lift  leverage  conviction  zhangs_metric  \n",
       " 0    1.000000  0.090909     -40.0         inf      -1.428571  \n",
       " 1    0.833333  0.075758     -61.0       -60.0      -1.694444  \n",
       " 2    0.833333  0.075758     -61.0       -60.0      -1.694444  \n",
       " 3    0.750000  0.125000     -42.0       -20.0       0.000000  \n",
       " 4    1.000000  0.125000     -42.0         inf      -3.500000  \n",
       " 5    0.833333  0.075758     -61.0       -60.0      -1.694444  \n",
       " 6    1.000000  0.166667     -25.0         inf      -5.000000  \n",
       " 7    1.000000  0.125000     -35.0         inf      -2.333333  \n",
       " 8    0.833333  0.166667     -25.0       -24.0       0.000000  ,\n",
       " 'Apriori_TID_Diabetic-Data-Therayar':   antecedents consequents  antecedent support  consequent support  support  \\\n",
       " 0        (53)         (6)                 6.0                11.0      5.0   \n",
       " 1        (65)         (6)                 4.0                11.0      4.0   \n",
       " 2        (67)         (6)                 6.0                11.0      5.0   \n",
       " 3        (52)        (53)                 8.0                 6.0      6.0   \n",
       " 4        (53)        (52)                 6.0                 8.0      6.0   \n",
       " 5    (52, 53)         (6)                 6.0                11.0      5.0   \n",
       " 6     (52, 6)        (53)                 5.0                 6.0      5.0   \n",
       " 7     (53, 6)        (52)                 5.0                 8.0      5.0   \n",
       " 8        (53)     (52, 6)                 6.0                 5.0      5.0   \n",
       " \n",
       "    confidence      lift  leverage  conviction  zhangs_metric  \n",
       " 0    0.833333  0.075758     -61.0       -60.0      -1.694444  \n",
       " 1    1.000000  0.090909     -40.0         inf      -1.428571  \n",
       " 2    0.833333  0.075758     -61.0       -60.0      -1.694444  \n",
       " 3    0.750000  0.125000     -42.0       -20.0       0.000000  \n",
       " 4    1.000000  0.125000     -42.0         inf      -3.500000  \n",
       " 5    0.833333  0.075758     -61.0       -60.0      -1.694444  \n",
       " 6    1.000000  0.166667     -25.0         inf      -5.000000  \n",
       " 7    1.000000  0.125000     -35.0         inf      -2.333333  \n",
       " 8    0.833333  0.166667     -25.0       -24.0       0.000000  ,\n",
       " 'Relim_Diabetic-Data-Therayar':   antecedents consequents  antecedent support  consequent support  support  \\\n",
       " 0        (65)         (6)                 4.0                11.0      4.0   \n",
       " 1        (52)        (53)                 8.0                 6.0      6.0   \n",
       " 2        (53)        (52)                 6.0                 8.0      6.0   \n",
       " 3    (52, 53)         (6)                 6.0                11.0      5.0   \n",
       " 4     (52, 6)        (53)                 5.0                 6.0      5.0   \n",
       " 5     (53, 6)        (52)                 5.0                 8.0      5.0   \n",
       " 6        (53)     (52, 6)                 6.0                 5.0      5.0   \n",
       " 7        (53)         (6)                 6.0                11.0      5.0   \n",
       " 8        (67)         (6)                 6.0                11.0      5.0   \n",
       " \n",
       "    confidence      lift  leverage  conviction  zhangs_metric  \n",
       " 0    1.000000  0.090909     -40.0         inf      -1.428571  \n",
       " 1    0.750000  0.125000     -42.0       -20.0       0.000000  \n",
       " 2    1.000000  0.125000     -42.0         inf      -3.500000  \n",
       " 3    0.833333  0.075758     -61.0       -60.0      -1.694444  \n",
       " 4    1.000000  0.166667     -25.0         inf      -5.000000  \n",
       " 5    1.000000  0.125000     -35.0         inf      -2.333333  \n",
       " 6    0.833333  0.166667     -25.0       -24.0       0.000000  \n",
       " 7    0.833333  0.075758     -61.0       -60.0      -1.694444  \n",
       " 8    0.833333  0.075758     -61.0       -60.0      -1.694444  ,\n",
       " 'Eclat_Diabetic-Data-Therayar':   antecedents consequents  antecedent support  consequent support  support  \\\n",
       " 0        (65)         (6)                 4.0                11.0      4.0   \n",
       " 1        (52)        (53)                 8.0                 6.0      6.0   \n",
       " 2        (53)        (52)                 6.0                 8.0      6.0   \n",
       " 3        (53)         (6)                 6.0                11.0      5.0   \n",
       " 4    (52, 53)         (6)                 6.0                11.0      5.0   \n",
       " 5     (52, 6)        (53)                 5.0                 6.0      5.0   \n",
       " 6     (53, 6)        (52)                 5.0                 8.0      5.0   \n",
       " 7        (53)     (52, 6)                 6.0                 5.0      5.0   \n",
       " 8        (67)         (6)                 6.0                11.0      5.0   \n",
       " \n",
       "    confidence      lift  leverage  conviction  zhangs_metric  \n",
       " 0    1.000000  0.090909     -40.0         inf      -1.428571  \n",
       " 1    0.750000  0.125000     -42.0       -20.0       0.000000  \n",
       " 2    1.000000  0.125000     -42.0         inf      -3.500000  \n",
       " 3    0.833333  0.075758     -61.0       -60.0      -1.694444  \n",
       " 4    0.833333  0.075758     -61.0       -60.0      -1.694444  \n",
       " 5    1.000000  0.166667     -25.0         inf      -5.000000  \n",
       " 6    1.000000  0.125000     -35.0         inf      -2.333333  \n",
       " 7    0.833333  0.166667     -25.0       -24.0       0.000000  \n",
       " 8    0.833333  0.075758     -61.0       -60.0      -1.694444  ,\n",
       " 'Apriori_Tuberculosis-Data-Overall': Empty DataFrame\n",
       " Columns: [antecedents, consequents, antecedent support, consequent support, support, confidence, lift, leverage, conviction, zhangs_metric]\n",
       " Index: [],\n",
       " 'FPGrowth_itemsets_Tuberculosis-Data-Overall':    antecedents consequents  antecedent support  consequent support  support  \\\n",
       " 0         (51)         (6)                 5.0                16.0      5.0   \n",
       " 1         (65)        (68)                 6.0                 6.0      5.0   \n",
       " 2         (68)        (65)                 6.0                 6.0      5.0   \n",
       " 3         (81)         (6)                 7.0                16.0      5.0   \n",
       " 4         (54)         (6)                 7.0                16.0      5.0   \n",
       " 5         (53)         (6)                 7.0                16.0      7.0   \n",
       " 6         (53)        (52)                 7.0                10.0      6.0   \n",
       " 7     (52, 53)         (6)                 6.0                16.0      6.0   \n",
       " 8      (53, 6)        (52)                 7.0                10.0      6.0   \n",
       " 9         (53)     (52, 6)                 7.0                 9.0      6.0   \n",
       " 10        (52)         (6)                10.0                16.0      9.0   \n",
       " \n",
       "     confidence      lift  leverage  conviction  zhangs_metric  \n",
       " 0     1.000000  0.062500     -75.0         inf      -1.363636  \n",
       " 1     0.833333  0.138889     -31.0       -30.0      -5.166667  \n",
       " 2     0.833333  0.138889     -31.0       -30.0      -5.166667  \n",
       " 3     0.714286  0.044643    -107.0       -52.5      -1.389610  \n",
       " 4     0.714286  0.044643    -107.0       -52.5      -1.389610  \n",
       " 5     1.000000  0.062500    -105.0         inf      -1.666667  \n",
       " 6     0.857143  0.085714     -64.0       -63.0      -2.285714  \n",
       " 7     1.000000  0.062500     -90.0         inf      -1.500000  \n",
       " 8     0.857143  0.085714     -64.0       -63.0      -2.285714  \n",
       " 9     0.857143  0.095238     -57.0       -56.0      -2.714286  \n",
       " 10    0.900000  0.056250    -151.0      -150.0      -2.157143  ,\n",
       " 'Apriori_TID_Tuberculosis-Data-Overall':    antecedents consequents  antecedent support  consequent support  support  \\\n",
       " 0         (51)         (6)                 5.0                16.0      5.0   \n",
       " 1         (52)         (6)                10.0                16.0      9.0   \n",
       " 2         (53)         (6)                 7.0                16.0      7.0   \n",
       " 3         (54)         (6)                 7.0                16.0      5.0   \n",
       " 4         (81)         (6)                 7.0                16.0      5.0   \n",
       " 5         (53)        (52)                 7.0                10.0      6.0   \n",
       " 6         (65)        (68)                 6.0                 6.0      5.0   \n",
       " 7         (68)        (65)                 6.0                 6.0      5.0   \n",
       " 8     (52, 53)         (6)                 6.0                16.0      6.0   \n",
       " 9      (53, 6)        (52)                 7.0                10.0      6.0   \n",
       " 10        (53)     (52, 6)                 7.0                 9.0      6.0   \n",
       " \n",
       "     confidence      lift  leverage  conviction  zhangs_metric  \n",
       " 0     1.000000  0.062500     -75.0         inf      -1.363636  \n",
       " 1     0.900000  0.056250    -151.0      -150.0      -2.157143  \n",
       " 2     1.000000  0.062500    -105.0         inf      -1.666667  \n",
       " 3     0.714286  0.044643    -107.0       -52.5      -1.389610  \n",
       " 4     0.714286  0.044643    -107.0       -52.5      -1.389610  \n",
       " 5     0.857143  0.085714     -64.0       -63.0      -2.285714  \n",
       " 6     0.833333  0.138889     -31.0       -30.0      -5.166667  \n",
       " 7     0.833333  0.138889     -31.0       -30.0      -5.166667  \n",
       " 8     1.000000  0.062500     -90.0         inf      -1.500000  \n",
       " 9     0.857143  0.085714     -64.0       -63.0      -2.285714  \n",
       " 10    0.857143  0.095238     -57.0       -56.0      -2.714286  ,\n",
       " 'Relim_Tuberculosis-Data-Overall':    antecedents consequents  antecedent support  consequent support  support  \\\n",
       " 0         (51)         (6)                 5.0                16.0      5.0   \n",
       " 1         (65)        (68)                 6.0                 6.0      5.0   \n",
       " 2         (68)        (65)                 6.0                 6.0      5.0   \n",
       " 3         (53)        (52)                 7.0                10.0      6.0   \n",
       " 4     (52, 53)         (6)                 6.0                16.0      6.0   \n",
       " 5      (53, 6)        (52)                 7.0                10.0      6.0   \n",
       " 6         (53)     (52, 6)                 7.0                 9.0      6.0   \n",
       " 7         (53)         (6)                 7.0                16.0      7.0   \n",
       " 8         (54)         (6)                 7.0                16.0      5.0   \n",
       " 9         (81)         (6)                 7.0                16.0      5.0   \n",
       " 10        (52)         (6)                10.0                16.0      9.0   \n",
       " \n",
       "     confidence      lift  leverage  conviction  zhangs_metric  \n",
       " 0     1.000000  0.062500     -75.0         inf      -1.363636  \n",
       " 1     0.833333  0.138889     -31.0       -30.0      -5.166667  \n",
       " 2     0.833333  0.138889     -31.0       -30.0      -5.166667  \n",
       " 3     0.857143  0.085714     -64.0       -63.0      -2.285714  \n",
       " 4     1.000000  0.062500     -90.0         inf      -1.500000  \n",
       " 5     0.857143  0.085714     -64.0       -63.0      -2.285714  \n",
       " 6     0.857143  0.095238     -57.0       -56.0      -2.714286  \n",
       " 7     1.000000  0.062500    -105.0         inf      -1.666667  \n",
       " 8     0.714286  0.044643    -107.0       -52.5      -1.389610  \n",
       " 9     0.714286  0.044643    -107.0       -52.5      -1.389610  \n",
       " 10    0.900000  0.056250    -151.0      -150.0      -2.157143  ,\n",
       " 'Eclat_Tuberculosis-Data-Overall':    antecedents consequents  antecedent support  consequent support  support  \\\n",
       " 0         (51)         (6)                 5.0                16.0      5.0   \n",
       " 1         (65)        (68)                 6.0                 6.0      5.0   \n",
       " 2         (68)        (65)                 6.0                 6.0      5.0   \n",
       " 3         (53)        (52)                 7.0                10.0      6.0   \n",
       " 4         (53)         (6)                 7.0                16.0      7.0   \n",
       " 5     (52, 53)         (6)                 6.0                16.0      6.0   \n",
       " 6      (53, 6)        (52)                 7.0                10.0      6.0   \n",
       " 7         (53)     (52, 6)                 7.0                 9.0      6.0   \n",
       " 8         (54)         (6)                 7.0                16.0      5.0   \n",
       " 9         (81)         (6)                 7.0                16.0      5.0   \n",
       " 10        (52)         (6)                10.0                16.0      9.0   \n",
       " \n",
       "     confidence      lift  leverage  conviction  zhangs_metric  \n",
       " 0     1.000000  0.062500     -75.0         inf      -1.363636  \n",
       " 1     0.833333  0.138889     -31.0       -30.0      -5.166667  \n",
       " 2     0.833333  0.138889     -31.0       -30.0      -5.166667  \n",
       " 3     0.857143  0.085714     -64.0       -63.0      -2.285714  \n",
       " 4     1.000000  0.062500    -105.0         inf      -1.666667  \n",
       " 5     1.000000  0.062500     -90.0         inf      -1.500000  \n",
       " 6     0.857143  0.085714     -64.0       -63.0      -2.285714  \n",
       " 7     0.857143  0.095238     -57.0       -56.0      -2.714286  \n",
       " 8     0.714286  0.044643    -107.0       -52.5      -1.389610  \n",
       " 9     0.714286  0.044643    -107.0       -52.5      -1.389610  \n",
       " 10    0.900000  0.056250    -151.0      -150.0      -2.157143  ,\n",
       " 'Apriori_Tuberculosis-Data-Agathiyar': Empty DataFrame\n",
       " Columns: [antecedents, consequents, antecedent support, consequent support, support, confidence, lift, leverage, conviction, zhangs_metric]\n",
       " Index: [],\n",
       " 'FPGrowth_itemsets_Tuberculosis-Data-Agathiyar':    antecedents consequents  antecedent support  consequent support  support  \\\n",
       " 0         (51)         (6)                 4.0                12.0      4.0   \n",
       " 1         (51)        (52)                 4.0                 8.0      4.0   \n",
       " 2     (52, 51)         (6)                 4.0                12.0      4.0   \n",
       " 3      (51, 6)        (52)                 4.0                 8.0      4.0   \n",
       " 4         (51)     (52, 6)                 4.0                 8.0      4.0   \n",
       " 5         (81)         (6)                 5.0                12.0      5.0   \n",
       " 6         (81)        (52)                 5.0                 8.0      4.0   \n",
       " 7     (81, 52)         (6)                 4.0                12.0      4.0   \n",
       " 8      (81, 6)        (52)                 5.0                 8.0      4.0   \n",
       " 9         (81)     (52, 6)                 5.0                 8.0      4.0   \n",
       " 10        (53)         (6)                 6.0                12.0      6.0   \n",
       " 11        (53)        (52)                 6.0                 8.0      5.0   \n",
       " 12    (52, 53)         (6)                 5.0                12.0      5.0   \n",
       " 13     (53, 6)        (52)                 6.0                 8.0      5.0   \n",
       " 14        (53)     (52, 6)                 6.0                 8.0      5.0   \n",
       " 15        (52)         (6)                 8.0                12.0      8.0   \n",
       " \n",
       "     confidence      lift  leverage  conviction  zhangs_metric  \n",
       " 0     1.000000  0.083333     -44.0         inf      -1.375000  \n",
       " 1     1.000000  0.125000     -28.0         inf      -1.750000  \n",
       " 2     1.000000  0.083333     -44.0         inf      -1.375000  \n",
       " 3     1.000000  0.125000     -28.0         inf      -1.750000  \n",
       " 4     1.000000  0.125000     -28.0         inf      -1.750000  \n",
       " 5     1.000000  0.083333     -55.0         inf      -1.571429  \n",
       " 6     0.800000  0.100000     -36.0       -35.0      -1.800000  \n",
       " 7     1.000000  0.083333     -44.0         inf      -1.375000  \n",
       " 8     0.800000  0.100000     -36.0       -35.0      -1.800000  \n",
       " 9     0.800000  0.100000     -36.0       -35.0      -1.800000  \n",
       " 10    1.000000  0.083333     -66.0         inf      -1.833333  \n",
       " 11    0.833333  0.104167     -43.0       -42.0      -2.388889  \n",
       " 12    1.000000  0.083333     -55.0         inf      -1.571429  \n",
       " 13    0.833333  0.104167     -43.0       -42.0      -2.388889  \n",
       " 14    0.833333  0.104167     -43.0       -42.0      -2.388889  \n",
       " 15    1.000000  0.083333     -88.0         inf      -2.750000  ,\n",
       " 'Apriori_TID_Tuberculosis-Data-Agathiyar':    antecedents consequents  antecedent support  consequent support  support  \\\n",
       " 0         (51)         (6)                 4.0                12.0      4.0   \n",
       " 1         (52)         (6)                 8.0                12.0      8.0   \n",
       " 2         (53)         (6)                 6.0                12.0      6.0   \n",
       " 3         (81)         (6)                 5.0                12.0      5.0   \n",
       " 4         (51)        (52)                 4.0                 8.0      4.0   \n",
       " 5         (53)        (52)                 6.0                 8.0      5.0   \n",
       " 6         (81)        (52)                 5.0                 8.0      4.0   \n",
       " 7     (52, 51)         (6)                 4.0                12.0      4.0   \n",
       " 8      (51, 6)        (52)                 4.0                 8.0      4.0   \n",
       " 9         (51)     (52, 6)                 4.0                 8.0      4.0   \n",
       " 10    (52, 53)         (6)                 5.0                12.0      5.0   \n",
       " 11     (53, 6)        (52)                 6.0                 8.0      5.0   \n",
       " 12        (53)     (52, 6)                 6.0                 8.0      5.0   \n",
       " 13    (81, 52)         (6)                 4.0                12.0      4.0   \n",
       " 14     (81, 6)        (52)                 5.0                 8.0      4.0   \n",
       " 15        (81)     (52, 6)                 5.0                 8.0      4.0   \n",
       " \n",
       "     confidence      lift  leverage  conviction  zhangs_metric  \n",
       " 0     1.000000  0.083333     -44.0         inf      -1.375000  \n",
       " 1     1.000000  0.083333     -88.0         inf      -2.750000  \n",
       " 2     1.000000  0.083333     -66.0         inf      -1.833333  \n",
       " 3     1.000000  0.083333     -55.0         inf      -1.571429  \n",
       " 4     1.000000  0.125000     -28.0         inf      -1.750000  \n",
       " 5     0.833333  0.104167     -43.0       -42.0      -2.388889  \n",
       " 6     0.800000  0.100000     -36.0       -35.0      -1.800000  \n",
       " 7     1.000000  0.083333     -44.0         inf      -1.375000  \n",
       " 8     1.000000  0.125000     -28.0         inf      -1.750000  \n",
       " 9     1.000000  0.125000     -28.0         inf      -1.750000  \n",
       " 10    1.000000  0.083333     -55.0         inf      -1.571429  \n",
       " 11    0.833333  0.104167     -43.0       -42.0      -2.388889  \n",
       " 12    0.833333  0.104167     -43.0       -42.0      -2.388889  \n",
       " 13    1.000000  0.083333     -44.0         inf      -1.375000  \n",
       " 14    0.800000  0.100000     -36.0       -35.0      -1.800000  \n",
       " 15    0.800000  0.100000     -36.0       -35.0      -1.800000  ,\n",
       " 'Relim_Tuberculosis-Data-Agathiyar':    antecedents consequents  antecedent support  consequent support  support  \\\n",
       " 0         (51)        (52)                 4.0                 8.0      4.0   \n",
       " 1     (52, 51)         (6)                 4.0                12.0      4.0   \n",
       " 2      (51, 6)        (52)                 4.0                 8.0      4.0   \n",
       " 3         (51)     (52, 6)                 4.0                 8.0      4.0   \n",
       " 4         (51)         (6)                 4.0                12.0      4.0   \n",
       " 5         (81)        (52)                 5.0                 8.0      4.0   \n",
       " 6     (81, 52)         (6)                 4.0                12.0      4.0   \n",
       " 7      (81, 6)        (52)                 5.0                 8.0      4.0   \n",
       " 8         (81)     (52, 6)                 5.0                 8.0      4.0   \n",
       " 9         (81)         (6)                 5.0                12.0      5.0   \n",
       " 10        (53)        (52)                 6.0                 8.0      5.0   \n",
       " 11    (52, 53)         (6)                 5.0                12.0      5.0   \n",
       " 12     (53, 6)        (52)                 6.0                 8.0      5.0   \n",
       " 13        (53)     (52, 6)                 6.0                 8.0      5.0   \n",
       " 14        (53)         (6)                 6.0                12.0      6.0   \n",
       " 15        (52)         (6)                 8.0                12.0      8.0   \n",
       " \n",
       "     confidence      lift  leverage  conviction  zhangs_metric  \n",
       " 0     1.000000  0.125000     -28.0         inf      -1.750000  \n",
       " 1     1.000000  0.083333     -44.0         inf      -1.375000  \n",
       " 2     1.000000  0.125000     -28.0         inf      -1.750000  \n",
       " 3     1.000000  0.125000     -28.0         inf      -1.750000  \n",
       " 4     1.000000  0.083333     -44.0         inf      -1.375000  \n",
       " 5     0.800000  0.100000     -36.0       -35.0      -1.800000  \n",
       " 6     1.000000  0.083333     -44.0         inf      -1.375000  \n",
       " 7     0.800000  0.100000     -36.0       -35.0      -1.800000  \n",
       " 8     0.800000  0.100000     -36.0       -35.0      -1.800000  \n",
       " 9     1.000000  0.083333     -55.0         inf      -1.571429  \n",
       " 10    0.833333  0.104167     -43.0       -42.0      -2.388889  \n",
       " 11    1.000000  0.083333     -55.0         inf      -1.571429  \n",
       " 12    0.833333  0.104167     -43.0       -42.0      -2.388889  \n",
       " 13    0.833333  0.104167     -43.0       -42.0      -2.388889  \n",
       " 14    1.000000  0.083333     -66.0         inf      -1.833333  \n",
       " 15    1.000000  0.083333     -88.0         inf      -2.750000  ,\n",
       " 'Eclat_Tuberculosis-Data-Agathiyar':    antecedents consequents  antecedent support  consequent support  support  \\\n",
       " 0         (51)        (52)                 4.0                 8.0      4.0   \n",
       " 1         (51)         (6)                 4.0                12.0      4.0   \n",
       " 2     (52, 51)         (6)                 4.0                12.0      4.0   \n",
       " 3      (51, 6)        (52)                 4.0                 8.0      4.0   \n",
       " 4         (51)     (52, 6)                 4.0                 8.0      4.0   \n",
       " 5         (81)        (52)                 5.0                 8.0      4.0   \n",
       " 6         (81)         (6)                 5.0                12.0      5.0   \n",
       " 7     (81, 52)         (6)                 4.0                12.0      4.0   \n",
       " 8      (81, 6)        (52)                 5.0                 8.0      4.0   \n",
       " 9         (81)     (52, 6)                 5.0                 8.0      4.0   \n",
       " 10        (53)        (52)                 6.0                 8.0      5.0   \n",
       " 11        (53)         (6)                 6.0                12.0      6.0   \n",
       " 12    (52, 53)         (6)                 5.0                12.0      5.0   \n",
       " 13     (53, 6)        (52)                 6.0                 8.0      5.0   \n",
       " 14        (53)     (52, 6)                 6.0                 8.0      5.0   \n",
       " 15        (52)         (6)                 8.0                12.0      8.0   \n",
       " \n",
       "     confidence      lift  leverage  conviction  zhangs_metric  \n",
       " 0     1.000000  0.125000     -28.0         inf      -1.750000  \n",
       " 1     1.000000  0.083333     -44.0         inf      -1.375000  \n",
       " 2     1.000000  0.083333     -44.0         inf      -1.375000  \n",
       " 3     1.000000  0.125000     -28.0         inf      -1.750000  \n",
       " 4     1.000000  0.125000     -28.0         inf      -1.750000  \n",
       " 5     0.800000  0.100000     -36.0       -35.0      -1.800000  \n",
       " 6     1.000000  0.083333     -55.0         inf      -1.571429  \n",
       " 7     1.000000  0.083333     -44.0         inf      -1.375000  \n",
       " 8     0.800000  0.100000     -36.0       -35.0      -1.800000  \n",
       " 9     0.800000  0.100000     -36.0       -35.0      -1.800000  \n",
       " 10    0.833333  0.104167     -43.0       -42.0      -2.388889  \n",
       " 11    1.000000  0.083333     -66.0         inf      -1.833333  \n",
       " 12    1.000000  0.083333     -55.0         inf      -1.571429  \n",
       " 13    0.833333  0.104167     -43.0       -42.0      -2.388889  \n",
       " 14    0.833333  0.104167     -43.0       -42.0      -2.388889  \n",
       " 15    1.000000  0.083333     -88.0         inf      -2.750000  ,\n",
       " 'Apriori_Tuberculosis-Data-Therayar': Empty DataFrame\n",
       " Columns: [antecedents, consequents, antecedent support, consequent support, support, confidence, lift, leverage, conviction, zhangs_metric]\n",
       " Index: [],\n",
       " 'FPGrowth_itemsets_Tuberculosis-Data-Therayar':       antecedents consequents  antecedent support  consequent support  \\\n",
       " 0           (145)         (6)                 2.0                 5.0   \n",
       " 1           (118)        (67)                 2.0                 5.0   \n",
       " 2           (118)       (122)                 2.0                 4.0   \n",
       " 3       (67, 122)       (118)                 2.0                 2.0   \n",
       " 4       (67, 118)       (122)                 2.0                 4.0   \n",
       " ...           ...         ...                 ...                 ...   \n",
       " 51702        (54)       (122)                 3.0                 4.0   \n",
       " 51703   (67, 122)        (54)                 2.0                 3.0   \n",
       " 51704    (67, 54)       (122)                 2.0                 4.0   \n",
       " 51705     (6, 54)       (122)                 2.0                 4.0   \n",
       " 51706    (122, 6)        (54)                 2.0                 3.0   \n",
       " \n",
       "        support  confidence      lift  leverage  conviction  zhangs_metric  \n",
       " 0          2.0         1.0  0.200000      -8.0         inf      -1.333333  \n",
       " 1          2.0         1.0  0.200000      -8.0         inf      -1.333333  \n",
       " 2          2.0         1.0  0.250000      -6.0         inf      -1.500000  \n",
       " 3          2.0         1.0  0.500000      -2.0         inf       0.000000  \n",
       " 4          2.0         1.0  0.250000      -6.0         inf      -1.500000  \n",
       " ...        ...         ...       ...       ...         ...            ...  \n",
       " 51702      3.0         1.0  0.250000      -9.0         inf      -3.000000  \n",
       " 51703      2.0         1.0  0.333333      -4.0         inf      -2.000000  \n",
       " 51704      2.0         1.0  0.250000      -6.0         inf      -1.500000  \n",
       " 51705      2.0         1.0  0.250000      -6.0         inf      -1.500000  \n",
       " 51706      2.0         1.0  0.333333      -4.0         inf      -2.000000  \n",
       " \n",
       " [51707 rows x 10 columns],\n",
       " 'Apriori_TID_Tuberculosis-Data-Therayar':       antecedents                            consequents  antecedent support  \\\n",
       " 0            (11)                                    (6)                 2.0   \n",
       " 1            (64)                                    (6)                 2.0   \n",
       " 2           (138)                                    (6)                 3.0   \n",
       " 3           (145)                                    (6)                 2.0   \n",
       " 4            (11)                                   (54)                 2.0   \n",
       " ...           ...                                    ...                 ...   \n",
       " 51702    (83, 11)      (122, 54, 87, 68, 138, 6, 89, 64)                 2.0   \n",
       " 51703    (64, 11)      (122, 54, 87, 68, 138, 6, 89, 83)                 2.0   \n",
       " 51704    (83, 64)      (122, 54, 11, 87, 68, 138, 6, 89)                 2.0   \n",
       " 51705        (11)  (122, 54, 87, 68, 138, 6, 89, 83, 64)                 2.0   \n",
       " 51706        (64)  (122, 54, 87, 68, 138, 6, 89, 11, 83)                 2.0   \n",
       " \n",
       "        consequent support  support  confidence      lift  leverage  \\\n",
       " 0                     5.0      2.0         1.0  0.200000      -8.0   \n",
       " 1                     5.0      2.0         1.0  0.200000      -8.0   \n",
       " 2                     5.0      3.0         1.0  0.200000     -12.0   \n",
       " 3                     5.0      2.0         1.0  0.200000      -8.0   \n",
       " 4                     3.0      2.0         1.0  0.333333      -4.0   \n",
       " ...                   ...      ...         ...       ...       ...   \n",
       " 51702                 2.0      2.0         1.0  0.500000      -2.0   \n",
       " 51703                 2.0      2.0         1.0  0.500000      -2.0   \n",
       " 51704                 2.0      2.0         1.0  0.500000      -2.0   \n",
       " 51705                 2.0      2.0         1.0  0.500000      -2.0   \n",
       " 51706                 2.0      2.0         1.0  0.500000      -2.0   \n",
       " \n",
       "        conviction  zhangs_metric  \n",
       " 0             inf      -1.333333  \n",
       " 1             inf      -1.333333  \n",
       " 2             inf      -2.000000  \n",
       " 3             inf      -1.333333  \n",
       " 4             inf      -2.000000  \n",
       " ...           ...            ...  \n",
       " 51702         inf       0.000000  \n",
       " 51703         inf       0.000000  \n",
       " 51704         inf       0.000000  \n",
       " 51705         inf       0.000000  \n",
       " 51706         inf       0.000000  \n",
       " \n",
       " [51707 rows x 10 columns],\n",
       " 'Relim_Tuberculosis-Data-Therayar':       antecedents consequents  antecedent support  consequent support  \\\n",
       " 0            (11)        (64)                 2.0                 2.0   \n",
       " 1            (64)        (11)                 2.0                 2.0   \n",
       " 2        (11, 64)        (54)                 2.0                 3.0   \n",
       " 3        (54, 64)        (11)                 2.0                 2.0   \n",
       " 4        (54, 11)        (64)                 2.0                 2.0   \n",
       " ...           ...         ...                 ...                 ...   \n",
       " 51702    (122, 6)        (89)                 2.0                 3.0   \n",
       " 51703  (138, 122)         (6)                 2.0                 5.0   \n",
       " 51704    (122, 6)       (138)                 2.0                 3.0   \n",
       " 51705       (138)         (6)                 3.0                 5.0   \n",
       " 51706   (67, 138)         (6)                 2.0                 5.0   \n",
       " \n",
       "        support  confidence      lift  leverage  conviction  zhangs_metric  \n",
       " 0          2.0         1.0  0.500000      -2.0         inf       0.000000  \n",
       " 1          2.0         1.0  0.500000      -2.0         inf       0.000000  \n",
       " 2          2.0         1.0  0.333333      -4.0         inf      -2.000000  \n",
       " 3          2.0         1.0  0.500000      -2.0         inf       0.000000  \n",
       " 4          2.0         1.0  0.500000      -2.0         inf       0.000000  \n",
       " ...        ...         ...       ...       ...         ...            ...  \n",
       " 51702      2.0         1.0  0.333333      -4.0         inf      -2.000000  \n",
       " 51703      2.0         1.0  0.200000      -8.0         inf      -1.333333  \n",
       " 51704      2.0         1.0  0.333333      -4.0         inf      -2.000000  \n",
       " 51705      3.0         1.0  0.200000     -12.0         inf      -2.000000  \n",
       " 51706      2.0         1.0  0.200000      -8.0         inf      -1.333333  \n",
       " \n",
       " [51707 rows x 10 columns],\n",
       " 'Eclat_Tuberculosis-Data-Therayar':       antecedents consequents  antecedent support  consequent support  \\\n",
       " 0            (64)        (11)                 2.0                 2.0   \n",
       " 1            (11)        (64)                 2.0                 2.0   \n",
       " 2       (138, 64)        (11)                 2.0                 2.0   \n",
       " 3        (11, 64)       (138)                 2.0                 3.0   \n",
       " 4       (138, 11)        (64)                 2.0                 2.0   \n",
       " ...           ...         ...                 ...                 ...   \n",
       " 51702    (67, 87)       (122)                 2.0                 4.0   \n",
       " 51703   (67, 122)        (87)                 2.0                 3.0   \n",
       " 51704    (122, 6)        (89)                 2.0                 3.0   \n",
       " 51705     (89, 6)       (122)                 2.0                 4.0   \n",
       " 51706   (122, 89)         (6)                 2.0                 5.0   \n",
       " \n",
       "        support  confidence      lift  leverage  conviction  zhangs_metric  \n",
       " 0          2.0         1.0  0.500000      -2.0         inf       0.000000  \n",
       " 1          2.0         1.0  0.500000      -2.0         inf       0.000000  \n",
       " 2          2.0         1.0  0.500000      -2.0         inf       0.000000  \n",
       " 3          2.0         1.0  0.333333      -4.0         inf      -2.000000  \n",
       " 4          2.0         1.0  0.500000      -2.0         inf       0.000000  \n",
       " ...        ...         ...       ...       ...         ...            ...  \n",
       " 51702      2.0         1.0  0.250000      -6.0         inf      -1.500000  \n",
       " 51703      2.0         1.0  0.333333      -4.0         inf      -2.000000  \n",
       " 51704      2.0         1.0  0.333333      -4.0         inf      -2.000000  \n",
       " 51705      2.0         1.0  0.250000      -6.0         inf      -1.500000  \n",
       " 51706      2.0         1.0  0.200000      -8.0         inf      -1.333333  \n",
       " \n",
       " [51707 rows x 10 columns]}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "association_rules_dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
