{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from spmf import Spmf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing\n",
    "data = pd.read_csv(r'../initial-data/Herbals and preperations.csv', encoding='latin-1')\n",
    "data = data.apply(lambda x: x.str.lower() if x.dtype == \"object\" else x)\n",
    "data=data.dropna(subset=['bot_name'])\n",
    "data['bot_name'] = data['bot_name'].str.strip()\n",
    "\n",
    "data['author'] = data['author'].dropna(axis=0).str.strip()\n",
    "data = data.apply(lambda x: x.str.lower() if x.dtype == \"object\" else x)\n",
    "data=data.dropna(subset=['bot_name'])\n",
    "data['bot_name'] = data['bot_name'].str.strip()\n",
    "columns_to_remove = ['herb_part', 'taste', 'potency', 'ultimate_taste', 'inherent_action']\n",
    "data = data.drop(columns=columns_to_remove)\n",
    "\n",
    "data.loc[data.bot_name.isin(['terminalia chebula', 'terminalia bellarica', 'phyllanthus emblica']), 'bot_name'] = 'triphala'\n",
    "data.loc[data.bot_name.isin(['piper nigrum', 'piper longum', 'zingiber officinale']), 'bot_name'] = 'trikatu'\n",
    "data.loc[(data.disease_category == 'diabetes') & (data.bot_name == 'saccharum officinarum'), 'bot_name'] = 'tinospora cordifolia'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert all unique values in bot_name to a new series to be used as id\n",
    "bot_name = data['bot_name'].unique()\n",
    "bot_name = pd.Series(bot_name)\n",
    "bot_name = bot_name.reset_index()\n",
    "bot_name.columns = ['id', 'bot_name']\n",
    "bot_name['id'] = bot_name['id'] + 1\n",
    "if not os.path.exists(f'./split-data'):\n",
    "    os.makedirs(f'./split-data')\n",
    "bot_name.to_csv(r'./split-data/ids.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting\n",
    "\n",
    "data_dia = data.loc[data['disease_category'].apply(lambda x: x in ['diab/ tb ', 'diabetes'])].copy()\n",
    "data_tub =  data.loc[data['disease_category'].apply(lambda x: x in ['diab/ tb ', 'tuberculosis '])].copy()\n",
    "data_dia_aga = data_dia.loc[data_dia['author'].apply(lambda x: x in ['agathiyar'])]\n",
    "data_dia_the = data_dia.loc[data_dia['author'].apply(lambda x: x in ['therayar'])]\n",
    "data_tub_aga = data_tub.loc[data_tub['author'].apply(lambda x: x in ['agathiyar'])]\n",
    "data_tub_the = data_tub.loc[data_tub['author'].apply(lambda x: x in ['therayar'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_split_data(data, name):\n",
    "    # group using the id instead of name\n",
    "    data = pd.merge(data, bot_name, on='bot_name', how='left')\n",
    "    # Groupby drug and output id of all bot_names instead of name in the text file\n",
    "    def remove_duplicates(row):\n",
    "        numbers = row.split()\n",
    "        unique_numbers = list(set(numbers))\n",
    "        return ' '.join(unique_numbers)\n",
    "    grouped_data = data.groupby('drug')['id'].apply(lambda x: ' '.join(x.astype(str))).reset_index()\n",
    "    grouped_data['id'] = grouped_data['id'].apply(remove_duplicates)\n",
    "    # grouped_data = data.groupby('drug')['bot_name'].apply(lambda x: ' '.join(x)).reset_index()\n",
    "    # grouped_data\n",
    "    # # Save the result to a text file\n",
    "    with open(f'./split-data/{name}.txt', 'w') as f:\n",
    "        for index, row in grouped_data.iterrows():\n",
    "            f.write(row['id'] + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = {\n",
    "    'Diabetic-Data-Overall': data_dia,\n",
    "    'Diabetic-Data-Agathiyar': data_dia_aga,\n",
    "    'Diabetic-Data-Therayar': data_dia_the,\n",
    "    'Tuberculosis-Data-Overall': data_tub,\n",
    "    'Tuberculosis-Data-Agathiyar': data_tub_aga,\n",
    "    'Tuberculosis-Data-Therayar': data_tub_the\n",
    "    }\n",
    "for name, data in all_data.items():\n",
    "    write_split_data(data, name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def runSPMF(algorithm, data, name):\n",
    "    # Create algorithm folder if not exists\n",
    "    if not os.path.exists(f'./output-data/{algorithm}'):\n",
    "        os.makedirs(f'./output-data/{algorithm}')\n",
    "    # Run SPMF\n",
    "    os.system( f\"java -jar spmf.jar run {algorithm} ./split-data/{name}.txt ./output-data/{algorithm}/{name}.txt 15%\")\n",
    "    # Read the result from the output txt file\n",
    "    with open(f'./output-data/{algorithm}/{name}.txt', 'r') as f:\n",
    "        # Read output in format => 52 53  #SUP: \n",
    "        result = f.read()\n",
    "    # Split the result into lines\n",
    "    result = result.split('\\n')\n",
    "    out_dic = {}\n",
    "    for row in result:\n",
    "        # Get the bot_name and support value\n",
    "        if not row:\n",
    "            continue\n",
    "        values = row.split(' #SUP: ')\n",
    "        out_dic[str(values[0])] = values[1]\n",
    "    # Out_dic to df\n",
    "    out_df = pd.DataFrame.from_dict(out_dic, orient='index').reset_index()\n",
    "    # Rename columns\n",
    "    out_df.columns = ['bot_name', 'support']\n",
    "    \n",
    "    def to_bot_name(row):\n",
    "        ids = row.split()\n",
    "        bot_names = []\n",
    "        for id in ids:\n",
    "            bot_names.append(bot_name.loc[bot_name['id'] == int(id), 'bot_name'].values[0])\n",
    "        return bot_names\n",
    "    \n",
    "    out_df['bot_name'] = out_df['bot_name'].apply(to_bot_name)\n",
    "    return out_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">/media/harsh/Docs Volume/Documents/Data Science Community/herbal-analysis/spmf/spmf.jar\n",
      "=============  APRIORI - STATS =============\n",
      " Candidates count : 10\n",
      " The algorithm stopped at size 2\n",
      " Frequent itemsets count : 4\n",
      " Maximum memory usage : 7.812141418457031 mb\n",
      " Total time ~ 8 ms\n",
      "===================================================\n",
      ">/media/harsh/Docs Volume/Documents/Data Science Community/herbal-analysis/spmf/spmf.jar\n",
      "=============  FP-GROWTH 2.42 - STATS =============\n",
      " Transactions count from database : 58\n",
      " Max memory usage: 7.813987731933594 mb \n",
      " Frequent itemsets count : 4\n",
      " Total time ~ 16 ms\n",
      "===================================================\n",
      ">/media/harsh/Docs Volume/Documents/Data Science Community/herbal-analysis/spmf/spmf.jar\n",
      "=============  APRIORI TID v2.12 - STATS =============\n",
      " Transactions count from database : 58\n",
      " Frequent itemsets count : 4\n",
      " Maximum memory usage : 7.8110809326171875 mb\n",
      " Total time ~ 21 ms\n",
      "===================================================\n",
      ">/media/harsh/Docs Volume/Documents/Data Science Community/herbal-analysis/spmf/spmf.jar\n",
      "========== RELIM - STATS ============\n",
      " Number of frequent  itemsets: 4\n",
      " Total time ~: 12 ms\n",
      " Max memory:7.813987731933594\n",
      "=====================================\n",
      ">/media/harsh/Docs Volume/Documents/Data Science Community/herbal-analysis/spmf/spmf.jar\n",
      "=============  ECLAT v0.96r18 - STATS =============\n",
      " Transactions count from database : 58\n",
      " Frequent itemsets count : 4\n",
      " Total time ~ 15 ms\n",
      " Maximum memory usage : 7.826728820800781 mb\n",
      "===================================================\n",
      ">/media/harsh/Docs Volume/Documents/Data Science Community/herbal-analysis/spmf/spmf.jar\n",
      "=============  APRIORI - STATS =============\n",
      " Candidates count : 6\n",
      " The algorithm stopped at size 2\n",
      " Frequent itemsets count : 3\n",
      " Maximum memory usage : 7.551063537597656 mb\n",
      " Total time ~ 9 ms\n",
      "===================================================\n",
      ">/media/harsh/Docs Volume/Documents/Data Science Community/herbal-analysis/spmf/spmf.jar\n",
      "=============  FP-GROWTH 2.42 - STATS =============\n",
      " Transactions count from database : 34\n",
      " Max memory usage: 7.82672119140625 mb \n",
      " Frequent itemsets count : 3\n",
      " Total time ~ 10 ms\n",
      "===================================================\n",
      ">/media/harsh/Docs Volume/Documents/Data Science Community/herbal-analysis/spmf/spmf.jar\n",
      "=============  APRIORI TID v2.12 - STATS =============\n",
      " Transactions count from database : 34\n",
      " Frequent itemsets count : 3\n",
      " Maximum memory usage : 7.551063537597656 mb\n",
      " Total time ~ 8 ms\n",
      "===================================================\n",
      ">/media/harsh/Docs Volume/Documents/Data Science Community/herbal-analysis/spmf/spmf.jar\n",
      "========== RELIM - STATS ============\n",
      " Number of frequent  itemsets: 3\n",
      " Total time ~: 9 ms\n",
      " Max memory:7.8110809326171875\n",
      "=====================================\n",
      ">/media/harsh/Docs Volume/Documents/Data Science Community/herbal-analysis/spmf/spmf.jar\n",
      "=============  ECLAT v0.96r18 - STATS =============\n",
      " Transactions count from database : 34\n",
      " Frequent itemsets count : 3\n",
      " Total time ~ 4 ms\n",
      " Maximum memory usage : 7.811134338378906 mb\n",
      "===================================================\n",
      ">/media/harsh/Docs Volume/Documents/Data Science Community/herbal-analysis/spmf/spmf.jar\n",
      "=============  APRIORI - STATS =============\n",
      " Candidates count : 45\n",
      " The algorithm stopped at size 2\n",
      " Frequent itemsets count : 9\n",
      " Maximum memory usage : 7.551063537597656 mb\n",
      " Total time ~ 5 ms\n",
      "===================================================\n",
      ">/media/harsh/Docs Volume/Documents/Data Science Community/herbal-analysis/spmf/spmf.jar\n",
      "=============  FP-GROWTH 2.42 - STATS =============\n",
      " Transactions count from database : 25\n",
      " Max memory usage: 7.82672119140625 mb \n",
      " Frequent itemsets count : 16\n",
      " Total time ~ 9 ms\n",
      "===================================================\n",
      ">/media/harsh/Docs Volume/Documents/Data Science Community/herbal-analysis/spmf/spmf.jar\n",
      "=============  APRIORI TID v2.12 - STATS =============\n",
      " Transactions count from database : 25\n",
      " Frequent itemsets count : 16\n",
      " Maximum memory usage : 7.551063537597656 mb\n",
      " Total time ~ 6 ms\n",
      "===================================================\n",
      ">/media/harsh/Docs Volume/Documents/Data Science Community/herbal-analysis/spmf/spmf.jar\n",
      "========== RELIM - STATS ============\n",
      " Number of frequent  itemsets: 16\n",
      " Total time ~: 13 ms\n",
      " Max memory:7.8110809326171875\n",
      "=====================================\n",
      ">/media/harsh/Docs Volume/Documents/Data Science Community/herbal-analysis/spmf/spmf.jar\n",
      "=============  ECLAT v0.96r18 - STATS =============\n",
      " Transactions count from database : 25\n",
      " Frequent itemsets count : 16\n",
      " Total time ~ 5 ms\n",
      " Maximum memory usage : 7.811088562011719 mb\n",
      "===================================================\n",
      ">/media/harsh/Docs Volume/Documents/Data Science Community/herbal-analysis/spmf/spmf.jar\n",
      "=============  APRIORI - STATS =============\n",
      " Candidates count : 105\n",
      " The algorithm stopped at size 2\n",
      " Frequent itemsets count : 14\n",
      " Maximum memory usage : 7.551063537597656 mb\n",
      " Total time ~ 12 ms\n",
      "===================================================\n",
      ">/media/harsh/Docs Volume/Documents/Data Science Community/herbal-analysis/spmf/spmf.jar\n",
      "=============  FP-GROWTH 2.42 - STATS =============\n",
      " Transactions count from database : 32\n",
      " Max memory usage: 7.826728820800781 mb \n",
      " Frequent itemsets count : 22\n",
      " Total time ~ 10 ms\n",
      "===================================================\n",
      ">/media/harsh/Docs Volume/Documents/Data Science Community/herbal-analysis/spmf/spmf.jar\n",
      "=============  APRIORI TID v2.12 - STATS =============\n",
      " Transactions count from database : 32\n",
      " Frequent itemsets count : 22\n",
      " Maximum memory usage : 7.811073303222656 mb\n",
      " Total time ~ 9 ms\n",
      "===================================================\n",
      ">/media/harsh/Docs Volume/Documents/Data Science Community/herbal-analysis/spmf/spmf.jar\n",
      "========== RELIM - STATS ============\n",
      " Number of frequent  itemsets: 22\n",
      " Total time ~: 15 ms\n",
      " Max memory:8.550979614257812\n",
      "=====================================\n",
      ">/media/harsh/Docs Volume/Documents/Data Science Community/herbal-analysis/spmf/spmf.jar\n",
      "=============  ECLAT v0.96r18 - STATS =============\n",
      " Transactions count from database : 32\n",
      " Frequent itemsets count : 22\n",
      " Total time ~ 10 ms\n",
      " Maximum memory usage : 7.811103820800781 mb\n",
      "===================================================\n",
      ">/media/harsh/Docs Volume/Documents/Data Science Community/herbal-analysis/spmf/spmf.jar\n",
      "=============  APRIORI - STATS =============\n",
      " Candidates count : 36\n",
      " The algorithm stopped at size 2\n",
      " Frequent itemsets count : 8\n",
      " Maximum memory usage : 7.551063537597656 mb\n",
      " Total time ~ 4 ms\n",
      "===================================================\n",
      ">/media/harsh/Docs Volume/Documents/Data Science Community/herbal-analysis/spmf/spmf.jar\n",
      "=============  FP-GROWTH 2.42 - STATS =============\n",
      " Transactions count from database : 21\n",
      " Max memory usage: 7.812049865722656 mb \n",
      " Frequent itemsets count : 18\n",
      " Total time ~ 7 ms\n",
      "===================================================\n",
      ">/media/harsh/Docs Volume/Documents/Data Science Community/herbal-analysis/spmf/spmf.jar\n",
      "=============  APRIORI TID v2.12 - STATS =============\n",
      " Transactions count from database : 21\n",
      " Frequent itemsets count : 18\n",
      " Maximum memory usage : 7.551063537597656 mb\n",
      " Total time ~ 8 ms\n",
      "===================================================\n",
      ">/media/harsh/Docs Volume/Documents/Data Science Community/herbal-analysis/spmf/spmf.jar\n",
      "========== RELIM - STATS ============\n",
      " Number of frequent  itemsets: 18\n",
      " Total time ~: 5 ms\n",
      " Max memory:7.813987731933594\n",
      "=====================================\n",
      ">/media/harsh/Docs Volume/Documents/Data Science Community/herbal-analysis/spmf/spmf.jar\n",
      "=============  ECLAT v0.96r18 - STATS =============\n",
      " Transactions count from database : 21\n",
      " Frequent itemsets count : 18\n",
      " Total time ~ 4 ms\n",
      " Maximum memory usage : 7.813682556152344 mb\n",
      "===================================================\n",
      ">/media/harsh/Docs Volume/Documents/Data Science Community/herbal-analysis/spmf/spmf.jar\n",
      "=============  APRIORI - STATS =============\n",
      " Candidates count : 253\n",
      " The algorithm stopped at size 2\n",
      " Frequent itemsets count : 22\n",
      " Maximum memory usage : 7.551063537597656 mb\n",
      " Total time ~ 6 ms\n",
      "===================================================\n",
      ">/media/harsh/Docs Volume/Documents/Data Science Community/herbal-analysis/spmf/spmf.jar\n",
      "=============  FP-GROWTH 2.42 - STATS =============\n",
      " Transactions count from database : 13\n",
      " Max memory usage: 8.028984069824219 mb \n",
      " Frequent itemsets count : 1112\n",
      " Total time ~ 23 ms\n",
      "===================================================\n",
      ">/media/harsh/Docs Volume/Documents/Data Science Community/herbal-analysis/spmf/spmf.jar\n",
      "=============  APRIORI TID v2.12 - STATS =============\n",
      " Transactions count from database : 13\n",
      " Frequent itemsets count : 1112\n",
      " Maximum memory usage : 7.551063537597656 mb\n",
      " Total time ~ 56 ms\n",
      "===================================================\n",
      ">/media/harsh/Docs Volume/Documents/Data Science Community/herbal-analysis/spmf/spmf.jar\n",
      "========== RELIM - STATS ============\n",
      " Number of frequent  itemsets: 1112\n",
      " Total time ~: 59 ms\n",
      " Max memory:14.028984069824219\n",
      "=====================================\n",
      ">/media/harsh/Docs Volume/Documents/Data Science Community/herbal-analysis/spmf/spmf.jar\n",
      "=============  ECLAT v0.96r18 - STATS =============\n",
      " Transactions count from database : 13\n",
      " Frequent itemsets count : 1112\n",
      " Total time ~ 22 ms\n",
      " Maximum memory usage : 8.290977478027344 mb\n",
      "===================================================\n"
     ]
    }
   ],
   "source": [
    "all_data_itemset = {}\n",
    "for name, data in all_data.items():\n",
    "    all_data_itemset['Apriori_'+ name] = runSPMF('Apriori', data, name)\n",
    "    all_data_itemset['FPGrowth_itemsets_' + name] = runSPMF('FPGrowth_itemsets', data, name)\n",
    "    all_data_itemset['Apriori_TID_' + name] = runSPMF('Apriori_TID', data, name)\n",
    "    all_data_itemset['Relim_' + name] = runSPMF('Relim', data, name)\n",
    "    all_data_itemset['Eclat_' + name] = runSPMF('Eclat', data, name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def generate_association_rules(data, min_support=2, min_confidence=0.7):\n",
    "  \"\"\"\n",
    "  Generates association rules from a DataFrame of frequent itemsets.\n",
    "\n",
    "  Args:\n",
    "    data: A pandas DataFrame with columns \"bot_name\" (list of items) and \"support\" (frequency).\n",
    "    min_support: Minimum support threshold.\n",
    "    min_confidence: Minimum confidence threshold.\n",
    "\n",
    "  Returns:\n",
    "    A pandas DataFrame with columns \"antecedent\", \"consequent\", \"support_antecedent\", \"support_union\", \"confidence\".\n",
    "  \"\"\"\n",
    "\n",
    "  rules = []\n",
    "  for i in range(1, len(data)):\n",
    "    for j in range(i):\n",
    "      antecedent = set(data.loc[i, \"bot_name\"])\n",
    "      consequent = set(data.loc[j, \"bot_name\"]) - antecedent\n",
    "      if len(consequent) > 0:\n",
    "        support_antecedent = data.loc[i, \"support\"]\n",
    "        support_union = data.loc[i, \"support\"] + data.loc[j, \"support\"]\n",
    "        confidence = support_union / support_antecedent\n",
    "        if confidence >= min_confidence:\n",
    "          rules.append((antecedent, consequent, support_antecedent, support_union, confidence))\n",
    "\n",
    "  rules = [rule for rule in rules if rule[3] >= min_support]\n",
    "\n",
    "  return pd.DataFrame(rules, columns=[\"antecedent\", \"consequent\", \"support_antecedent\", \"support_union\", \"confidence\"])\n",
    "\n",
    "# Example usage\n",
    "association_rules = generate_association_rules(all_data_itemset['Relim_Tuberculosis-Data-Therayar'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>antecedent</th>\n",
       "      <th>consequent</th>\n",
       "      <th>support_antecedent</th>\n",
       "      <th>support_union</th>\n",
       "      <th>confidence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{saccharum officinarum, cuminum cyminum, myris...</td>\n",
       "      <td>{abies spectabilis}</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{saccharum officinarum, cuminum cyminum, myris...</td>\n",
       "      <td>{abies spectabilis}</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{saccharum officinarum, cuminum cyminum, myris...</td>\n",
       "      <td>{plectranthus vettiveroides}</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{saccharum officinarum, cuminum cyminum, myris...</td>\n",
       "      <td>{plectranthus vettiveroides}</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{saccharum officinarum, cuminum cyminum, myris...</td>\n",
       "      <td>{plectranthus vettiveroides, trikatu}</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>613453</th>\n",
       "      <td>{costus speciosus}</td>\n",
       "      <td>{abies spectabilis}</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>1.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>613454</th>\n",
       "      <td>{costus speciosus}</td>\n",
       "      <td>{trikatu, abies spectabilis}</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>1.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>613455</th>\n",
       "      <td>{costus speciosus}</td>\n",
       "      <td>{abies spectabilis}</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>1.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>613456</th>\n",
       "      <td>{costus speciosus}</td>\n",
       "      <td>{trikatu}</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>613457</th>\n",
       "      <td>{costus speciosus}</td>\n",
       "      <td>{trikatu}</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>1.6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>613458 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               antecedent  \\\n",
       "0       {saccharum officinarum, cuminum cyminum, myris...   \n",
       "1       {saccharum officinarum, cuminum cyminum, myris...   \n",
       "2       {saccharum officinarum, cuminum cyminum, myris...   \n",
       "3       {saccharum officinarum, cuminum cyminum, myris...   \n",
       "4       {saccharum officinarum, cuminum cyminum, myris...   \n",
       "...                                                   ...   \n",
       "613453                                 {costus speciosus}   \n",
       "613454                                 {costus speciosus}   \n",
       "613455                                 {costus speciosus}   \n",
       "613456                                 {costus speciosus}   \n",
       "613457                                 {costus speciosus}   \n",
       "\n",
       "                                   consequent  support_antecedent  \\\n",
       "0                         {abies spectabilis}                   2   \n",
       "1                         {abies spectabilis}                   2   \n",
       "2                {plectranthus vettiveroides}                   2   \n",
       "3                {plectranthus vettiveroides}                   2   \n",
       "4       {plectranthus vettiveroides, trikatu}                   2   \n",
       "...                                       ...                 ...   \n",
       "613453                    {abies spectabilis}                   5   \n",
       "613454           {trikatu, abies spectabilis}                   5   \n",
       "613455                    {abies spectabilis}                   5   \n",
       "613456                              {trikatu}                   5   \n",
       "613457                              {trikatu}                   5   \n",
       "\n",
       "        support_union  confidence  \n",
       "0                   4         2.0  \n",
       "1                   4         2.0  \n",
       "2                   4         2.0  \n",
       "3                   4         2.0  \n",
       "4                   4         2.0  \n",
       "...               ...         ...  \n",
       "613453              9         1.8  \n",
       "613454              7         1.4  \n",
       "613455              7         1.4  \n",
       "613456             10         2.0  \n",
       "613457              8         1.6  \n",
       "\n",
       "[613458 rows x 5 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "association_rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlxtend.frequent_patterns import association_rules\n",
    "import pandas as pd\n",
    "\n",
    "df = all_data_itemset['Relim_Tuberculosis-Data-Therayar']\n",
    "\n",
    "# Transform the data into a binary format for association rule mining\n",
    "def encode_units(x):\n",
    "    return 1 if x else 0\n",
    "\n",
    "# Apply one-hot encoding to the 'bot_name' column\n",
    "basket_sets = df['bot_name'].apply(lambda x: pd.Series({item: encode_units(item in x) for item in x}))\n",
    "\n",
    "# Generate frequent itemsets using Apriori algorithm\n",
    "frequent_itemsets = basket_sets.dropna().astype(int)\n",
    "\n",
    "# Generate association rules\n",
    "rules = association_rules(frequent_itemsets, metric=\"confidence\", min_threshold=0.5)\n",
    "\n",
    "# Display the association rules\n",
    "print(rules)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
